{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "sys.path.append('../src')  # Assuming 'process_data.py' is in the 'src' directory\n",
    "from pre_process_data import pre_process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get project main directory path using pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/tesal/Desktop/Teresa/code_projects/sentiment_analysis_twitter_climate_change/docs')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = Path().resolve().parent\n",
    "current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Define stopwords and lemmatizer\n",
    "stpwrd = stopwords.words('english')\n",
    "stpwrd.extend(string.punctuation)  # add punctuation symbols to stopwords: '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "stpwrd.extend(['rt', 'co', 'https', 'http', 'amp', 'us'])  # add common twitter terms to stopwords\n",
    "commwords = ['climate', 'change', 'global', 'warming','like', 'ðÿ', 'il', 'le', 'gt']\n",
    "stpwrd.extend(commwords) # add common words to stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'rt', 'co', 'https', 'http', 'amp', 'us', 'climate', 'change', 'global', 'warming', 'like', 'ðÿ', 'il', 'le', 'gt']\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "print(stpwrd)\n",
    "print(len(stpwrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwrd = set(stopwords.words('english'))\n",
    "stpwrd.update(string.punctuation)\n",
    "stpwrd.update(['rt', 'co', 'https', 'http', 'amp', 'us'])\n",
    "commwords = ['climate', 'change', 'global', 'warming','like', 'ðÿ', 'il', 'le', 'gt']\n",
    "stpwrd.update(commwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{')', \"don't\", 'down', 'both', 'having', 'few', 'will', 'mustn', 'you', 'such', \"'\", ';', 'yourselves', 'below', 'over', '}', 'like', 'of', 'ma', ':', 'who', 'le', 'own', '$', 'their', 'our', 'y', 'than', 'won', 'me', ']', 'global', 'that', 'at', 'for', 'doing', 'what', \"you'd\", '!', '<', \"wouldn't\", 'between', 'am', 'yourself', '\"', '=', '`', 'http', 'against', 'all', 'didn', 'nor', 'they', '>', 'theirs', 'did', 'but', \"didn't\", '+', 'll', 'we', 'are', 'her', \"isn't\", 'in', 'if', \"hadn't\", 'these', 'is', 'my', 'whom', 'into', 'don', 'off', 'because', 'm', \"aren't\", 'only', 'under', 'us', \"you're\", \"shan't\", 'up', 'then', '|', 'those', 'before', 'were', 'just', 'o', 'no', \"weren't\", \"she's\", 'why', 'myself', 'should', 'hasn', 'ours', 'wasn', '_', \"mightn't\", 'shan', 'by', 'them', 'with', 't', 'have', 'needn', 'not', \"shouldn't\", 'being', \"needn't\", 'i', 's', 'during', 'too', 'its', \"won't\", 're', 'very', 'do', 'his', '?', 'most', '.', 'warming', 'hers', 'rt', 'from', 'on', '-', 'himself', 'each', 'same', 'there', 'the', '%', \"doesn't\", ',', 'until', 'itself', 'above', 'other', \"it's\", 'yours', \"that'll\", '[', 'out', 'after', 'isn', \"couldn't\", 'this', \"mustn't\", '*', 'climate', 'been', 'mightn', 'aren', 'herself', 'shouldn', 'she', 'be', \"hasn't\", 'themselves', 'wouldn', 'change', 'it', 'can', \"should've\", '{', 'so', 'any', 'through', '(', \"wasn't\", 'co', 'amp', 'he', 'doesn', '\\\\', '~', 'https', '/', 'was', 'once', '#', 'does', 'further', \"you'll\", 'has', 'as', 'd', 'hadn', 'weren', 'an', 've', '@', 'had', '^', 'haven', 'again', 'or', '&', 'il', 'to', 'gt', 'couldn', 'which', 'and', 'ain', 'ourselves', 'how', 'now', \"you've\", 'some', 'a', 'while', 'him', \"haven't\", 'ðÿ', 'when', 'more', 'here', 'where', 'your', 'about'}\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "print(stpwrd)\n",
    "print(len(stpwrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "with open('../models/LogisticRegression.pkl','rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tesal\\Desktop\\Teresa\\code_projects\\sentiment_analysis_twitter_climate_change\\docs\\../src\\pre_process_data.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_message'] = clean_df['tokens'].apply(untokener)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "#process data\n",
    "clean_df, data_X, data_y = pre_process_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = clean_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "# predict\n",
    "pred = model.predict(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.30723579091531616\n",
      "Precision:  0.4285294993409726\n",
      "Recall:  0.30723579091531616\n",
      "F1 Score:  0.3287082175321616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate accuracy, precission and recall\n",
    "accuracy = accuracy_score(gt, pred)\n",
    "precision = precision_score(gt, pred, average='weighted')\n",
    "recall = recall_score(gt, pred, average='weighted')\n",
    "f1 = f1_score(gt, pred, average='weighted')\n",
    "\n",
    "print('Accuracy: ', accuracy, )\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1 Score: ', f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "\n",
    "#from src.pre_process_data import pre_process_data\n",
    "\n",
    "# Define text perturbation\n",
    "aug = nac.KeyboardAug(aug_word_max=1) # Insert realistic keystroke errors\n",
    "def typo(input):\n",
    "    output = aug.augment(input)\n",
    "    return output[0]\n",
    "\n",
    "# read in the test data\n",
    "test_path = '../data/test.csv'\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "model_path = '../models/RandomForestClassifier.pkl'\n",
    "# load model\n",
    "with open(model_path,'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tesal\\Desktop\\Teresa\\code_projects\\sentiment_analysis_twitter_climate_change\\docs\\../src\\pre_process_data.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['clean_message'] = clean_df['tokens'].apply(untokener)\n"
     ]
    }
   ],
   "source": [
    "# pre-process the data\n",
    "clean_df, x, gt_y = pre_process_data(test_df, data_type='test')\n",
    "\n",
    "# same but add typos\n",
    "typo_df = clean_df.copy()\n",
    "typo_df['message'] = typo_df['message'].apply(typo)\n",
    "typo_clean_df, typo_x, __ = pre_process_data(typo_df, data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8762, 8762)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_df), len(typo_clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run inference\n",
    "y_pred = model.predict(x)\n",
    "y_pred_typo = model.predict(typo_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>perturbed_tweet</th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_typo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @OP_Society: This sea turtle population is ...</td>\n",
       "      <td>RT @ OP_Society: This sea turtle population is...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @LeeCamp: 44% of honey bee colonies died la...</td>\n",
       "      <td>RT @ LeeCamp: 44% of honey bee colonies died l...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Trump and his people are not only climate chan...</td>\n",
       "      <td>Trump and his people are not only climate chan...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>RT @ClimateReality: The @Energy Dep’t doesn’t ...</td>\n",
       "      <td>RT @ ClimateReality: The @ Energy Dep ’ t does...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>@CaseyNeistat Thoughts on #BeforetheFlood + gl...</td>\n",
       "      <td>@ CaseyNeistat Thoughts on # BSBorethet:pod + ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_tweet  \\\n",
       "0   RT @OP_Society: This sea turtle population is ...   \n",
       "19  RT @LeeCamp: 44% of honey bee colonies died la...   \n",
       "34  Trump and his people are not only climate chan...   \n",
       "57  RT @ClimateReality: The @Energy Dep’t doesn’t ...   \n",
       "60  @CaseyNeistat Thoughts on #BeforetheFlood + gl...   \n",
       "\n",
       "                                      perturbed_tweet  gt  pred  pred_typo  \n",
       "0   RT @ OP_Society: This sea turtle population is...   2     2          1  \n",
       "19  RT @ LeeCamp: 44% of honey bee colonies died l...   2     0          1  \n",
       "34  Trump and his people are not only climate chan...   2     0          1  \n",
       "57  RT @ ClimateReality: The @ Energy Dep ’ t does...   2     1          3  \n",
       "60  @ CaseyNeistat Thoughts on # BSBorethet:pod + ...   1     2          1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe whith the \"tweet\" column from clean_df, the \"target\" column from clean_df, and the \"tweet\" column from typo_clean_df\n",
    "comparison_df = pd.concat([clean_df['message'], typo_clean_df['message'], clean_df['target']], axis=1)\n",
    "comparison_df.columns = ['original_tweet', 'perturbed_tweet', 'gt']\n",
    "comparison_df['pred'] = y_pred\n",
    "comparison_df['pred_typo'] = y_pred_typo\n",
    "\n",
    "# select rows where the prediction is different\n",
    "diff_df = comparison_df[comparison_df['pred'] != comparison_df['pred_typo']]\n",
    "diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.23213878110020544\n",
      "Accuracy with typos:  0.23168226432321387\n",
      "Difference rate:  3.20%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the % of tweets that are classified differently\n",
    "diff_rate = len(diff_df)/len(comparison_df)*100\n",
    "\n",
    "\n",
    "# Calculate the accuracy\n",
    "gt = clean_df[\"target\"]\n",
    "accuracy = accuracy_score(gt, y_pred)\n",
    "accuracy_typo = accuracy_score(gt, y_pred_typo)\n",
    "\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Accuracy with typos: ', accuracy_typo)\n",
    "print('Difference rate: ', \"{:.2f}%\".format(diff_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe whith the \"tweet\" column from clean_df, the \"target\" column from clean_df, and the \"tweet\" column from typo_clean_df\n",
    "comparison_df = pd.concat([clean_df['message'], typo_clean_df['message'], clean_df['target']], axis=1)\n",
    "comparison_df.columns = ['original_tweet', 'perturbed_tweet', 'gt']\n",
    "comparison_df['pred'] = y_pred\n",
    "comparison_df['pred_typo'] = y_pred_typo\n",
    "\n",
    "# select rows where the prediction is different\n",
    "diff_df = comparison_df[comparison_df['pred'] != comparison_df['pred_typo']]\n",
    "\n",
    "# Write out interesting cases\n",
    "with open(\"failure_modes.txt\",\"w\") as outfile:\n",
    "    outfile.write(diff_df.head(4).to_markdown(index=False))\n",
    "\n",
    "# Calculate the % of tweets that are classified differently\n",
    "diff_rate = len(diff_df)/len(comparison_df)\n",
    "\n",
    "# Calculate the accuracy\n",
    "gt = clean_df[\"target\"]\n",
    "accuracy = accuracy_score(gt, y_pred)\n",
    "accuracy_typo = accuracy_score(gt, y_pred_typo)\n",
    "\n",
    "\n",
    "# Write results to file\n",
    "with open(\"test_score.json\", 'w') as outfile:\n",
    "    json.dump({ \"accuracy_original dataset\": accuracy,\n",
    "               \"accuracy_typo dataset\": accuracy_typo,\n",
    "               \"Percentage tweets that were classified differently\": diff_rate\n",
    "               }, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatenlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
